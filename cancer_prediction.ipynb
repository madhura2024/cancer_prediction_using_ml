{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQyZ7yQAyBF+OeFZPsXzfC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhura2024/cancer_prediction_using_ml/blob/main/cancer_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFBtlzrjs4ns",
        "outputId": "70ce5319-c191-495f-89d8-996a8576615e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logical regression  0.9629629629629629\n",
            "Random Forest regression 0.9629629629629629\n",
            "svm regression  0.9629629629629629\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 - 1s - 180ms/step - accuracy: 0.0996 - loss: 1.0294 - val_accuracy: 0.1587 - val_loss: 0.8711\n",
            "Epoch 2/50\n",
            "8/8 - 0s - 18ms/step - accuracy: 0.1315 - loss: 0.8586 - val_accuracy: 0.2857 - val_loss: 0.7587\n",
            "Epoch 3/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.3227 - loss: 0.7287 - val_accuracy: 0.4603 - val_loss: 0.6725\n",
            "Epoch 4/50\n",
            "8/8 - 0s - 38ms/step - accuracy: 0.5578 - loss: 0.6333 - val_accuracy: 0.6667 - val_loss: 0.6039\n",
            "Epoch 5/50\n",
            "8/8 - 0s - 26ms/step - accuracy: 0.8526 - loss: 0.5575 - val_accuracy: 0.9365 - val_loss: 0.5430\n",
            "Epoch 6/50\n",
            "8/8 - 0s - 38ms/step - accuracy: 0.9243 - loss: 0.4917 - val_accuracy: 0.9524 - val_loss: 0.4851\n",
            "Epoch 7/50\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.9482 - loss: 0.4293 - val_accuracy: 0.9524 - val_loss: 0.4279\n",
            "Epoch 8/50\n",
            "8/8 - 0s - 24ms/step - accuracy: 0.9562 - loss: 0.3699 - val_accuracy: 0.9524 - val_loss: 0.3738\n",
            "Epoch 9/50\n",
            "8/8 - 0s - 28ms/step - accuracy: 0.9522 - loss: 0.3171 - val_accuracy: 0.9524 - val_loss: 0.3272\n",
            "Epoch 10/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9482 - loss: 0.2737 - val_accuracy: 0.9524 - val_loss: 0.2890\n",
            "Epoch 11/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9522 - loss: 0.2381 - val_accuracy: 0.9524 - val_loss: 0.2588\n",
            "Epoch 12/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9522 - loss: 0.2099 - val_accuracy: 0.9524 - val_loss: 0.2349\n",
            "Epoch 13/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9522 - loss: 0.1880 - val_accuracy: 0.9524 - val_loss: 0.2168\n",
            "Epoch 14/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9522 - loss: 0.1716 - val_accuracy: 0.9524 - val_loss: 0.2026\n",
            "Epoch 15/50\n",
            "8/8 - 0s - 18ms/step - accuracy: 0.9522 - loss: 0.1589 - val_accuracy: 0.9524 - val_loss: 0.1915\n",
            "Epoch 16/50\n",
            "8/8 - 0s - 19ms/step - accuracy: 0.9562 - loss: 0.1490 - val_accuracy: 0.9524 - val_loss: 0.1827\n",
            "Epoch 17/50\n",
            "8/8 - 0s - 12ms/step - accuracy: 0.9562 - loss: 0.1412 - val_accuracy: 0.9524 - val_loss: 0.1759\n",
            "Epoch 18/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.1355 - val_accuracy: 0.9524 - val_loss: 0.1700\n",
            "Epoch 19/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9562 - loss: 0.1302 - val_accuracy: 0.9524 - val_loss: 0.1657\n",
            "Epoch 20/50\n",
            "8/8 - 0s - 18ms/step - accuracy: 0.9562 - loss: 0.1264 - val_accuracy: 0.9524 - val_loss: 0.1618\n",
            "Epoch 21/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9522 - loss: 0.1233 - val_accuracy: 0.9524 - val_loss: 0.1584\n",
            "Epoch 22/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9522 - loss: 0.1201 - val_accuracy: 0.9524 - val_loss: 0.1557\n",
            "Epoch 23/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9522 - loss: 0.1179 - val_accuracy: 0.9683 - val_loss: 0.1532\n",
            "Epoch 24/50\n",
            "8/8 - 0s - 18ms/step - accuracy: 0.9562 - loss: 0.1156 - val_accuracy: 0.9683 - val_loss: 0.1511\n",
            "Epoch 25/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9562 - loss: 0.1141 - val_accuracy: 0.9683 - val_loss: 0.1486\n",
            "Epoch 26/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9562 - loss: 0.1119 - val_accuracy: 0.9683 - val_loss: 0.1473\n",
            "Epoch 27/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9562 - loss: 0.1104 - val_accuracy: 0.9683 - val_loss: 0.1457\n",
            "Epoch 28/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9562 - loss: 0.1091 - val_accuracy: 0.9683 - val_loss: 0.1447\n",
            "Epoch 29/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.1076 - val_accuracy: 0.9683 - val_loss: 0.1434\n",
            "Epoch 30/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9562 - loss: 0.1062 - val_accuracy: 0.9683 - val_loss: 0.1420\n",
            "Epoch 31/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.1049 - val_accuracy: 0.9683 - val_loss: 0.1411\n",
            "Epoch 32/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.1037 - val_accuracy: 0.9683 - val_loss: 0.1402\n",
            "Epoch 33/50\n",
            "8/8 - 0s - 15ms/step - accuracy: 0.9602 - loss: 0.1024 - val_accuracy: 0.9683 - val_loss: 0.1393\n",
            "Epoch 34/50\n",
            "8/8 - 0s - 15ms/step - accuracy: 0.9602 - loss: 0.1015 - val_accuracy: 0.9683 - val_loss: 0.1388\n",
            "Epoch 35/50\n",
            "8/8 - 0s - 18ms/step - accuracy: 0.9602 - loss: 0.1003 - val_accuracy: 0.9683 - val_loss: 0.1376\n",
            "Epoch 36/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.0992 - val_accuracy: 0.9683 - val_loss: 0.1374\n",
            "Epoch 37/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9602 - loss: 0.0983 - val_accuracy: 0.9683 - val_loss: 0.1368\n",
            "Epoch 38/50\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9562 - loss: 0.0970 - val_accuracy: 0.9683 - val_loss: 0.1358\n",
            "Epoch 39/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9562 - loss: 0.0961 - val_accuracy: 0.9683 - val_loss: 0.1353\n",
            "Epoch 40/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9562 - loss: 0.0950 - val_accuracy: 0.9683 - val_loss: 0.1345\n",
            "Epoch 41/50\n",
            "8/8 - 0s - 18ms/step - accuracy: 0.9562 - loss: 0.0941 - val_accuracy: 0.9683 - val_loss: 0.1337\n",
            "Epoch 42/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.0930 - val_accuracy: 0.9683 - val_loss: 0.1331\n",
            "Epoch 43/50\n",
            "8/8 - 0s - 12ms/step - accuracy: 0.9562 - loss: 0.0921 - val_accuracy: 0.9683 - val_loss: 0.1326\n",
            "Epoch 44/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.0915 - val_accuracy: 0.9683 - val_loss: 0.1315\n",
            "Epoch 45/50\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9562 - loss: 0.0904 - val_accuracy: 0.9683 - val_loss: 0.1318\n",
            "Epoch 46/50\n",
            "8/8 - 0s - 16ms/step - accuracy: 0.9562 - loss: 0.0896 - val_accuracy: 0.9683 - val_loss: 0.1312\n",
            "Epoch 47/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.0885 - val_accuracy: 0.9683 - val_loss: 0.1308\n",
            "Epoch 48/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.0877 - val_accuracy: 0.9683 - val_loss: 0.1309\n",
            "Epoch 49/50\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9562 - loss: 0.0868 - val_accuracy: 0.9683 - val_loss: 0.1306\n",
            "Epoch 50/50\n",
            "8/8 - 0s - 23ms/step - accuracy: 0.9562 - loss: 0.0860 - val_accuracy: 0.9683 - val_loss: 0.1298\n",
            "deep learning  0.9629629629629629\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install -q pandas scikit-learn tensorflow\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# deep learning tensor flow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BreastCancer.csv\")\n",
        "# print(model.columns)\n",
        "model[model.select_dtypes(include='object').columns] = model.select_dtypes(include='object').apply(pd.Series.str.strip)\n",
        "model = model.drop(columns=['Id'])\n",
        "model = model.dropna().drop_duplicates()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  check names of columns ,\n",
        "# if strip used axis = 1 has to be used\n",
        "#  error=ignore if column name doesnt exist\n",
        "# fit_tranform to just feed data to x train and only transform to find data for y train\n",
        "# drop columns that are irrelevant , if doesn't exist error=ignore\n",
        "\n",
        "x = model.drop('Class', axis=1)\n",
        "y = model['Class']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=11)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# scale to set scale , remove outliers , differences\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The model may still run, but the results can be inaccurate or unstable.\n",
        "# It’s like stopping a test before finishing — the model didn’t \"learn\" enough\n",
        "logreg = LogisticRegression(max_iter=10000, random_state=11)\n",
        "logreg.fit(x_train_scaled, y_train)\n",
        "y_pred = logreg.predict(x_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"logical regression \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "forest = RandomForestClassifier(random_state=11)\n",
        "forest.fit(x_train_scaled, y_train)\n",
        "y_pred_forest = forest.predict(x_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Random Forest regression\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "svm = SVC(kernel='rbf', probability=True, random_state=11)\n",
        "svm.fit(x_train_scaled, y_train)\n",
        "y_pred_svm = svm.predict(x_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"svm regression \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# encode all to be safe\n",
        "# le = LabelEncoder()\n",
        "# y_encode= le.fit_transform(y)     but unnecessary here since already integer value no string so all good .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# tensorflow: The main library we’re using to make the smart model.\n",
        "# Sequential: Lets us build a model step by step, layer by layer.      (this is the order)\n",
        "# Dense: A layer where every \"neuron\" connects to every input (a basic building block of the model).             (Make the first layer with 32 thinking units)\n",
        "# Finally, give me 1 output — either 0 or 1.\"\n",
        "# sigmoid squishes the result between 0 and 1, like a probability.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(x_train_scaled.shape[1],)),\n",
        "                                                                                                  # (relu helps the model learn better — like saying \"ignore negatives, keep positives.\")\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Use a smart way to improve yourself.” (adam is like a smart tutor)\n",
        "# binary because it’s a yes/no problem)\n",
        "# accuracy']: “While you're learning, show me how often you’re right.”\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  in logical regression max_iter determines model to read data 1000 ,, to learn properly , here we have epoch = 50 (learn 50 times)   batch size=32\n",
        "model.fit(\n",
        "    x_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# accuracy\n",
        "print(\"deep learning \", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "take input"
      ],
      "metadata": {
        "id": "srUU0xNAPdFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_user_input():\n",
        "\n",
        "    raw = input(\"Paste all 9 numbers (separated by space or comma):\\n\")\n",
        "\n",
        "\n",
        "    values = [float(x) for x in raw.replace(\",\", \" \").split()]\n",
        "\n",
        "\n",
        "    if len(values) != 9:\n",
        "     print(\"You must enter exactly 9 values.\")\n",
        "     return\n",
        "\n",
        "\n",
        "    values_scaled = scaler.transform([values])\n",
        "\n",
        "\n",
        "    pred1 = logreg.predict(values_scaled)[0]\n",
        "    pred2 = forest.predict(values_scaled)[0]\n",
        "    pred3 = svm.predict(values_scaled)[0]\n",
        "\n",
        "    import numpy as np\n",
        "    values_tf = np.array([values_scaled[0]])\n",
        "    pred4 = 1 if model.predict(values_tf)[0][0] > 0.5 else 0\n",
        "\n",
        "    print(\"\\n--- Predictions ---\")\n",
        "    if pred1 == 1:\n",
        "        print(\"Logistic Regression: Malignant\")\n",
        "    else:\n",
        "        print(\"Logistic Regression: Benign\")\n",
        "\n",
        "    if pred2 == 1:\n",
        "        print(\"Random Forest: Malignant\")\n",
        "    else:\n",
        "        print(\"Random Forest: Benign\")\n",
        "\n",
        "    if pred3 == 1:\n",
        "        print(\"SVM: Malignant\")\n",
        "    else:\n",
        "        print(\"SVM: Benign\")\n",
        "\n",
        "    if pred4 == 1:\n",
        "        print(\"TensorFlow DL Model: Malignant\")\n",
        "    else:\n",
        "        print(\"TensorFlow DL Model: Benign\")\n",
        "\n",
        "predict_user_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcUC8w0wPfPJ",
        "outputId": "80c21c23-a3de-4fa3-b3fb-5932820ef014"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste all 9 numbers (separated by space or comma):\n",
            "1,2,3,4,5,6,7,8,9\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Predictions ---\n",
            "Logistic Regression: Malignant\n",
            "Random Forest: Malignant\n",
            "SVM: Malignant\n",
            "TensorFlow DL Model: Malignant\n"
          ]
        }
      ]
    }
  ]
}